---
title: "SVM to predict AcP"
author: "Kirsten Zimbardi"
date: "26 May 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=F, message=F, error=F)
#clean workspace
rm(list=ls())
```

## Playing with SVM to predict academic performance

loading data...  
```{r, echo=FALSE}
#packages
require(reshape2)
require(dplyr)
require(caTools)
require(e1071)
require(neuralnet)

# ? should convert to github repo

#path = "/Users/KirstenZ/Dropbox/UQ/FeedbackAnalytics/Usage paper/Analysis" #MacAir
path = "/Users/zimbardi/Dropbox/UQ/FeedbackAnalytics/Usage paper/Analysis/" #iMac

#functions
source(paste0(path, "UQM functions.R"))
source(paste0(path, "HelperFunctions.R"))
#path = "/Users/KirstenZ/Dropbox/UQ/FeedbackAnalytics/Usage paper/Analysis" #MacAir
path = "/Users/zimbardi/Dropbox/UQ/FeedbackAnalytics/MachineLearningSandbox/" #iMac
source(paste0(path, "HelperFunctionsMachineLearning.R"))

#path = "/Users/KirstenZ/Dropbox/UQ/FeedbackAnalytics/Usage paper/Analysis" #MacAir
path = "/Users/zimbardi/Dropbox/UQ/FeedbackAnalytics/Usage paper/Analysis/" #iMac
ProjectID = read.csv(paste0(path, "/Data Stage 1/ProjectIDs.csv"))
projects()

#data
folder = paste0(path, "/Data Stage 2/")
demog = uqm.csv("demog")
#AcP = uqm.csv("AcPdf")
SubID.index = uqm.csv("SubIDindex")

# Don't need these yet
#FbP = uqm.csv("FbPdf")
#FbU = uqm.csv("FbUdf")
AcPFbUbins = uqm.csv("AcPFbUbins")
#mt = uqm.csv("MarkingTimes")

FbPsum = uqm.csv("FbPsummary") #Check GitHub repo for deleted explaination
AcP.FbU.FbP = merge(FbPsum, AcPFbUbins, by="SubmissionID")

#Generalising course names for pubilcation
demog = gen(demog, 13, 14)
#AcP = gen(AcP, 7, 8)
#FbP = gen(FbP, 15, 16)
#FbU = gen(FbU, 22, 23)
#AcPFbUbins = gen(AcPFbUbins, 7, 8)
SubID.index = gen(SubID.index, 4, 5)
#mt = gen(mt, 7, 8)
AcP.FbU.FbP = gen(AcP.FbU.FbP, 15, 16)

```


Turning MarkerID and open.bin into Factors for machine learning analysis -   
NB had to remove both at next step coz can't aggregate factors during dcast. Would need to delete duplicates (StudentID+report) to include these in machine learning models  
```{r}
df = AcP.FbU.FbP

df$MarkerID = as.factor(df$MarkerID) 
df$open.bin = as.factor(df$open.bin)

AcP.FbU.FbP = df

# checking for duplicate records (StudentID+report) within a single semester

df = subset(AcP.FbU.FbP, course == "Level 1" & sem == "Semester 1")
sub.count = with(df, table(StudentID, report))
which(isTRUE(sub.count>1)) # no duplicate submissions - so don't need mean for dcast?

```


removing cases w missing data 
(svm will train but get errors during prediction if any feature contains NA or NaN)  
```{r}
df = AcP.FbU.FbP

#df2 = df[!rowSums(is.na(df)),] # drops data from 705 obs to 461! #actually most Nas (90) in OpenDuration.min, min(OpenDuration.min) > and open.bin shows 66, 44, 50 and 104 unopened for R0 -> R4, so convert NA's to 0

cols = c("OpenDuration.min")
for (i in 1:nrow(df)) {
  for (j in 1:length(cols)) {
    if (is.na(df[i,cols[j]])) {
      df[i,cols[j]] = 0
} } }

#df2 = df[!rowSums(is.na(df)),] # brings data back up to 609 obs :)

AcP.FbU.FbP = df
```


Subsetting rows to work with a single semester, then  
selecting variables to use as features and reshaping using StudentID as rows  
```{r}
#df = AcP.FbU.FbP
df = subset(AcP.FbU.FbP, course == "Level 1" & sem == "Semester 1")
#df.FinalGrade = melt(df[,c(1,13,17)], id=c("StudentID", "report"), value.name="Final.Grade")
#df2 = dcast(df.FinalGrade, StudentID~variable+report, mean)

#df columns = "StudentID", "report", "Final.Grade”, “Freehand”, “Highlight”, “Recording”, “Text”, “total.words”, “auidio.min”, “audio.words”, “txt.words”, “OpenDuration.min”, “open.bin”, “MarkerID" 
#dv = "Final.Grade”, “Freehand”, “Highlight”, “Recording”, “Text”, “total.words”, “auidio.min”, “audio.words”, “txt.words”, “OpenDuration.min”, “open.bin”, “MarkerID" 
df = df[,c(10,17,13,2:9,18,19,11)]
dv = names(df[,c(3:ncol(df))])
ls = NULL
for (i in 1:length(dv)) {
  ls[[i]] = melt(df[,c(1,2,(i+2))], id=c("StudentID", "report"), value.name=dv[i])
}

ls2 = NULL
for (i in 1:length(dv)) {
  ls2[[i]] = dcast(ls[[i]], StudentID~variable+report)
}

df2 = ls2[[1]]
for (i in 2:length(ls2)) {
  df2 = merge(df2, ls2[[i]], by = "StudentID", all.x=T)
}

# removing Na's so svm runs
#str(df2)
#names(df2)
#length(which(is.na(rowSums(df2[,2:41]))))
df2 = df2[-which(is.na(rowSums(df2[,2:41]))),]


for (i in 42:49) {
  df2[,i] = as.factor(df2[,i]) 
}


mach.learn = df2

```

add on the 'outcome' ie R3 = A and remove R3 Final.Grade from dep vars    
```{r}
df = mach.learn

df$y = as.factor(df$`Final.Grade_Report 3` > (41 * (100/48)))
#table(df[,37], df[,42]) #check

col = which(names(df) == "Final.Grade_Report 3")
mach.learn = df[,-col]

```


Split data into training, cv and test sets  
```{r}
df = mach.learn

stud.split = splitter(df$StudentID, 60)
df.train = df[which(df$StudentID %in% stud.split[[1]]),2:ncol(df)]
df.cv = df[which(df$StudentID %in% stud.split[[2]]),2:ncol(df)]
df.test = df[which(df$StudentID %in% stud.split[[3]]),2:ncol(df)]
```


svm  
```{r}
#df = df.train[,c(2:ncol(df.train))]
#df$y = as.logical(df$y)
svmfit <- svm(y ~., data=df.train)
print(svmfit)
#my_cols <- c("#00AFBB", "#E7B800")
#plot(svmfit, df) # can't plot coz >2 variables (high dimensionality data)
p <- predict(svmfit, df.cv)
p.cv = predict(svmfit, df.cv)
df.cv$p = p.cv
cm = as.data.frame.matrix(addmargins(with(df.cv, table(y, p))))

cmStats = conMatrixStats(cm)
cmStats

# tuning cost
tuned = tune(svm, y~., data = df.cv, ranges = list(cost=c(0.0001,0.001,0.01, 0.1, 1, 10, 100)))
summary(tuned)
# returns lowest cost but that gives worst performance on test data set - clearly overfitting?
svmfit.tuned <- svm(y ~., data=df.train, cost = 10)
print(svmfit.tuned)

p.test = predict(svmfit.tuned, df.test)
df.test$p = p.test
cm.test = as.data.frame.matrix(addmargins(with(df.test, table(y, p))))

cmStats = conMatrixStats(cm.test)
cmStats


```

So, pretty good (predicts with ~80% accuracy who will get an A for the final report and who won't). Next to generalise ie add in demographic data and reduce back to Report 1 (mark, feedback provision and use) so can use the model on 1st and 2nd year data, and would also have an earlier indication of performance on final report...  

First, reducing down to 1st and final to align/generalise  
```{r}
df = AcP.FbU.FbP

for (i in 1:nrow(df)) {
  if (df$course[i] == "Level 2" & df$final[i] == "nonfinal") {
    df$final[i] = "first"
  }
  if (df$course[i] == "Level 1" & df$report[i] == "Report 0") {
    df$final[i] = "first"
  }
   if (df$course[i] == "Level 1" & df$sem[i] == "Semester 2" & df$report[i] == "Report 1") {
    df$final[i] = "first"
  }
}

df2 = subset(df, final == "first" | final == "final") 

# check
length(which(duplicated(df2[,c("StudentID", "course", "sem", "report")])))

# Adding in demographic data  # not working... might need lookup table to merge in demographic data, or do it after re-shaped for first and final reports
df3 = merge(df2, demog, by=c("StudentID", "course", "sem"))

mach.learn2 = df2

```


Reducing variables and reshaping so that StudentID leads each row of features  
```{r}

df = mach.learn2



#dv = "Final.Grade”, “Freehand”, “Highlight”, “Recording”, “Text”, “total.words”, “auidio.min”, “audio.words”, “txt.words”, “OpenDuration.min”, “open.bin”, “MarkerID"
df = df[,c("StudentID","course", "sem", "final", "Final.Grade", "Freehand", "Highlight", "Recording", "Text", "total.words", "auidio.min", "audio.words", "txt.words", "OpenDuration.min", "open.bin", "MarkerID")]
#dv = names(df2[,c(3:ncol(df2))])
dv = c("Final.Grade", "Freehand", "Highlight", "Recording", "Text", "total.words", "auidio.min", "audio.words", "txt.words", "OpenDuration.min", "open.bin", "MarkerID")


cs = as.factor(paste(df$course, df$sem))
cs.ls = NULL
cs.ls = split(df, cs)

last.ls = NULL
for (l in 1:length(cs.ls)) 
{
  ls.11 = NULL
  for (i in 1:length(dv)) {
    ls.11[[i]] = melt(cs.ls[[l]][,c(1,4, (i+4))], id=c("StudentID", "final"), value.name = dv[i])
  }
  
  ls.11b = NULL
  for (i in 1:length(dv)) {
    ls.11b[[i]] = dcast(ls.11[[i]], StudentID~variable+final)
  }
  
  df2 = ls.11b[[1]]
  for (i in 2:length(ls.11b)) {
    df2 = merge(df2, ls.11b[[i]], by = "StudentID", all.x=T)
  }
  
  df2$cs = names(cs.ls)[l]
  last.ls[[l]] = df2
}
rm(ls.11, ls.11b, df2)

# not sure if this is still needed, or where it should go
#for (i in 42:49) {
#  df2[,i] = as.factor(df2[,i]) 
#}

df3 = rbind(last.ls[[1]], last.ls[[2]], last.ls[[3]], last.ls[[4]])

df4 = df3[!rowSums(is.na(df)),] # drops data from 1916 obs to 1763 - pretty good

mach.learn2 = df4

```

add on the 'outcome' ie final = A and remove R3 Final.Grade from dep vars    
```{r}
df = mach.learn2

df$y = as.factor(df$`Final.Grade_final` > 85)
#table(df[,37], df[,42]) #check

# not generalising well to grade bands, and need to adjust conMatrixStats function if y > 2 classes
#bins = c(0,49,64,74,84,100)
#df$y = as.factor(cut(df$`Final.Grade_final`, bins))
col = which(names(df) == "Final.Grade_final")
mach.learn2 = df[,-col]

```


Next, need to split for svm - but systematic random samples from each courseXsem
```{r}
df = mach.learn2

df$sID.cs = paste(df$StudentID, df$cs)
df = df[,c(1,27,2:26)]

stud.split = splitter(df$sID.cs, 60)
df.train = df[which(df$sID.cs %in% stud.split[[1]]),3:ncol(df)]
df.cv = df[which(df$sID.cs %in% stud.split[[2]]),3:ncol(df)]
df.test = df[which(df$sID.cs %in% stud.split[[3]]),3:ncol(df)]


```


svm  
```{r}

svmfit2 <- svm(y ~., data=df.train, cost=10)
print(svmfit2)
p <- predict(svmfit2, df.cv)
df.cv$p = p
cm = as.data.frame.matrix(addmargins(with(df.cv, table(y, p))))
cm # rows are actual values (y) and columns are prediction (p)
cmStats = conMatrixStats(cm)
cmStats
```


